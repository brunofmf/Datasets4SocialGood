{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Personality_Processes_GradientBoostedTrees.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPuN0AGloF7toYaY28BeLwl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brunofmf/Datasets4SocialGood/blob/master/Personality_Processes_GradientBoostedTrees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMjKFTdpevh4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Wed Mar 18 16:21:35 2020\n",
        "\n",
        "@author: brunofmf\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import KFold, RandomizedSearchCV\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, f1_score, precision_score, recall_score\n",
        "from sklearn.multioutput import MultiOutputRegressor, MultiOutputClassifier\n",
        "from xgboost import XGBRegressor, XGBClassifier\n",
        "import joblib\n",
        "import time\n",
        "import json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixhjbZPvzNla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "#####################################################\n",
        "#### Random seeds definition ########################\n",
        "#####################################################\n",
        "'''\n",
        "\n",
        "np.random.seed(91190530)\n",
        "#np.random.seed(95191227)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VOxJKfee2b5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "#####################################################\n",
        "#### File System Interaction ########################\n",
        "#####################################################\n",
        "'''\n",
        "\n",
        "def enable_save_to_drive():\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "        \n",
        "'''\n",
        "Read datasets from file system or from google drive\n",
        "Return with data augmentation if with_da is true\n",
        "'''\n",
        "def read_dataset(with_da, colab):\n",
        "    if colab:\n",
        "        #give permission to save to drive\n",
        "        enable_save_to_drive()\n",
        "        #load dataset\n",
        "        from google.colab import files\n",
        "        import io\n",
        "        uploaded = files.upload()\n",
        "        for fn in uploaded.keys():\n",
        "            print('Uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))\n",
        "        return pd.read_csv(io.BytesIO(uploaded[fn]))\n",
        "    else:\n",
        "        file_name = ('prepared_datasets/personality_final_WithDa_20200321.csv' if with_da else 'prepared_datasets/personality_final_NoDa_20200321.csv')\n",
        "        return pd.read_csv(file_name)\n",
        "\n",
        "'''\n",
        "Save file to file system or to google drive\n",
        "'''\n",
        "def save_file(name, results, trial, iteration, architecture, with_da, colab, testing=False):\n",
        "    if testing:\n",
        "        filename = name + '_Architecture' + str(architecture) + '_' + with_da + '_' + time.strftime(\"%Y%m%d%H%M\") + \".txt\"\n",
        "    else:\n",
        "        filename = name + '_Architecture' + str(architecture) + '_' + with_da + '_Trial' + str(trial) + '_Iteration' + str(iteration) + '_' + time.strftime(\"%Y%m%d%H%M\") + \".txt\"\n",
        "    if colab:\n",
        "        filepath = F'/content/gdrive/My Drive/Experiments/' + filename\n",
        "    else:\n",
        "        filepath = F'Experiments/' + filename\n",
        "    with open(filepath, 'w') as f:\n",
        "        f.write(json.dumps(results))\n",
        "        \n",
        "'''\n",
        "Save the best estimator found using nested-CV\n",
        "'''\n",
        "def save_best_estimator(best_estimator, architecture, with_da, colab):\n",
        "    filename = 'BestModel_Architecture' + str(architecture) + '_' + with_da + '_' + time.strftime(\"%Y%m%d%H%M\") + \".pkl\"\n",
        "    if colab:\n",
        "        filepath = F'/content/gdrive/My Drive/Experiments/' + filename\n",
        "    else:\n",
        "        filepath = F'Experiments/' + filename\n",
        "    joblib.dump(best_estimator, filepath)\n",
        "      \n",
        "'''\n",
        "Used to save CSVs (in particular, to save features' importance)\n",
        "'''\n",
        "def save_csv(df, architecture, with_da, colab, save_index=False):\n",
        "    filename = 'FeaturesImportance_Architecture' + str(architecture) + '_' + with_da + '_' + time.strftime(\"%Y%m%d%H%M\") + \".csv\"\n",
        "    if colab:\n",
        "        filepath = F'/content/gdrive/My Drive/Experiments/' + filename\n",
        "    else:\n",
        "        filepath = F'Experiments/' + filename\n",
        "    df.to_csv(filepath, index=save_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkO5h5kGfU_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "#####################################################\n",
        "#### Data Definition ################################\n",
        "#####################################################\n",
        "'''\n",
        "\n",
        "'''\n",
        "Returns a tuning dictionary (hyperparameter search space)\n",
        "'''\n",
        "def tuning_dictionary():\n",
        "    return {\n",
        "        'estimator__n_estimators': [300, 400, 500],\n",
        "        'estimator__max_depth': [4, 12, 18],\n",
        "        'estimator__eta': [0.01, 0.05, 0.1], #aka learning rate\n",
        "        'estimator__gamma': [.02, .04, .08],\n",
        "        'estimator__min_child_weight': [4, 6, 8],\n",
        "        'estimator__colsample_bytree': [0.2, 0.3]\n",
        "    }\n",
        "\n",
        "'''\n",
        "Split dataframe into X and y, depending on the architecture\n",
        "Returns (X, y)\n",
        "'''\n",
        "def split_x_y(df, architecture, testing=False):\n",
        "    df_aux = df.copy()\n",
        "    #if arch is 1 (regression) we want trait values and we drop binned traits. If arch is 2 (classifiers), it is the opposite\n",
        "    if architecture == 1:\n",
        "        df_aux.drop(df_aux.loc[:, 'extraversion_binned':'openess_binned'].columns, axis=1, inplace=True)\n",
        "    else:\n",
        "        df_aux.drop(df_aux.loc[:, 'extraversion_recalculated':'openess_recalculated'].columns, axis=1, inplace=True)\n",
        "    #which columns make our X (the one-hot encoded adjectives)\n",
        "    cols_X = pd.Series([('recalculated' not in col and 'binned' not in col) for col in df_aux.columns])\n",
        "    #split into X and y\n",
        "    #if testing, we will test the best estimator on the last 50 adjectives (not used to evaluate the model)\n",
        "    if testing:\n",
        "        X = df_aux.iloc[-50:, cols_X.values]\n",
        "        y = df_aux.iloc[-50:, ~cols_X.values]\n",
        "    else:\n",
        "        X = df_aux.loc[:, cols_X.values]\n",
        "        y = df_aux.loc[:, ~cols_X.values]\n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqHEWjoOzh6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "#####################################################\n",
        "#### Modelling and Fit ##############################\n",
        "#####################################################\n",
        "'''\n",
        "\n",
        "'''\n",
        "Dynamically build the gradient boosted estimator. If arch is 1 then XGBRegressor else XGBClassifier\n",
        "Returns a multi-output regressor/classifier which fits one regressor/classifier per label (we have 5 labels - the five traits)\n",
        "'''\n",
        "def build_model(architecture):\n",
        "    if architecture == 1:\n",
        "        estimator = XGBRegressor(\n",
        "            booster = 'gbtree', \n",
        "            objective = 'reg:squarederror',\n",
        "            eval_metric = 'rmse',\n",
        "            #tree_method='gpu_hist',\n",
        "            verbose=1)\n",
        "        multi_estimator = MultiOutputRegressor(estimator)\n",
        "    else:\n",
        "        estimator = XGBClassifier(\n",
        "            booster = 'gbtree',\n",
        "            objective = 'multi:softmax',\n",
        "            num_class = 3,\n",
        "            eval_metric = 'auc', #auc not gpu supported (https://xgboost.readthedocs.io/en/latest/gpu/index.html)\n",
        "            #tree_method='gpu_hist',\n",
        "            verbose=1)\n",
        "        multi_estimator = MultiOutputClassifier(estimator)\n",
        "    return multi_estimator\n",
        "\n",
        "'''\n",
        "Fitting the multi-output regressor/classifier\n",
        "Performs num_trials trials using nested-cross validation with outer k as outer_k_folds and inner k as inner_k_folds\n",
        "Returns the best_metric, best_estimator\n",
        "'''\n",
        "def find_best_model(model, X, y, param_grid, num_trials=2, outer_k_folds=2, inner_k_folds=3, num_iter=175, scoring='neg_root_mean_squared_error', architecture=1, with_da='no_da'):\n",
        "    #find the best model of all\n",
        "    best_metric = -100\n",
        "    #cv folds\n",
        "    outer_cv = KFold(n_splits=outer_k_folds, shuffle=True)\n",
        "    inner_cv = KFold(n_splits=inner_k_folds, shuffle=True)\n",
        "    #loop for each trial\n",
        "    for trial in range(1, num_trials+1):\n",
        "        #strore results per trial\n",
        "        results_dict = dict()\n",
        "        cv_results_dict = dict()\n",
        "        i = 1\n",
        "        for train, test in outer_cv.split(X):\n",
        "            #array to store scores per cv split \n",
        "            nested_scores_train = dict()\n",
        "            #to count time it took\n",
        "            start = time.time()\n",
        "            #performing inner cross validation here when looking for the best parameters\n",
        "            random_search = RandomizedSearchCV(estimator=model,\n",
        "                                param_distributions=param_grid, verbose=1, scoring=scoring,\n",
        "                                n_iter=num_iter, cv=inner_cv, n_jobs=-1)\n",
        "            #fitting training data\n",
        "            random_search.fit(X.loc[train,:], y.loc[train,:])\n",
        "            #saving results\n",
        "            run_time = time.time()-start\n",
        "            nested_scores_train['Best_Score'] = (-random_search.best_score_ if architecture == 1 else random_search.best_score_)\n",
        "            nested_scores_train['Evaluation_Score'] = (-random_search.score(X.loc[test,:], y.loc[test,:]) if architecture == 1 else random_search.score(X.loc[test,:], y.loc[test,:])) #evaluating on test data\n",
        "            nested_scores_train['Metrics_Score'] = model_testing(random_search.best_estimator_, X.loc[test,:], y.loc[test,:], architecture=architecture, with_da=DA_DESC)\n",
        "            nested_scores_train['Scorer'] = (scoring if architecture == 1 else str(random_search.scorer_))\n",
        "            nested_scores_train['Best_Params'] = random_search.best_params_\n",
        "            nested_scores_train['Run_Time'] = run_time\n",
        "            results_dict['Experiment_'+str(i)] = nested_scores_train\n",
        "            #store full CV results in case it is needed\n",
        "            cv_results_dict['Experiment_'+str(i)] = str(random_search.cv_results_)\n",
        "            #storing the best estimator\n",
        "            if(random_search.best_score_ > best_metric):\n",
        "                best_metric = random_search.best_score_\n",
        "                best_estimator = random_search.best_estimator_\n",
        "            #finishing fold\n",
        "            print('Outer iteration %d took %.3f s' %(i, run_time))\n",
        "            i += 1\n",
        "        #save the best scores after completing one trial\n",
        "        save_file('Personality', results_dict, trial, outer_k_folds, architecture, with_da, COLAB)\n",
        "        save_file('CV', cv_results_dict, trial, outer_k_folds, architecture, with_da, COLAB)\n",
        "    #store features importance for the best estimator (https://scikit-learn.org/stable/modules/ensemble.html)\n",
        "    #and https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html#sphx-glr-auto-examples-ensemble-plot-forest-importances-py\n",
        "    importances_arr = []\n",
        "    for clf in best_estimator.estimators_:\n",
        "        feature_importances = clf.feature_importances_\n",
        "        importances_arr.append(feature_importances)\n",
        "    df_features_importances = pd.DataFrame(data=importances_arr, columns=X.columns.values, index=y.columns.values).transpose()\n",
        "    df_features_importances.index.name = 'adjective'\n",
        "    df_features_importances = df_features_importances.reset_index()\n",
        "    #store to csv\n",
        "    save_csv(df_features_importances, architecture, with_da, COLAB)\n",
        "    #return data\n",
        "    return best_metric, best_estimator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TWdoPdgfXeK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "#####################################################\n",
        "#### Model Testing ##################################\n",
        "#####################################################\n",
        "'''\n",
        "\n",
        "'''\n",
        "Predict for some input values\n",
        "Saves a file containing some metrics regarding the predictions on the test fold\n",
        "Regression Metrics: MAE, MSE and RMSE global and for each trait\n",
        "Classification Metrics: Mean-Error, Micro-Macro F1, precision and recall\n",
        "'''\n",
        "def model_testing(estimator, X, y, architecture=1, with_da='no_da', colab=False, store_file=False):\n",
        "    #make predictions\n",
        "    predictions = estimator.predict(X)\n",
        "    #depending on the architecture, compute metrics\n",
        "    if architecture == 1:\n",
        "        #global metrics (for all traits together)\n",
        "        mae_global = mean_absolute_error(y, predictions, multioutput='uniform_average')\n",
        "        mse_global = mean_squared_error(y, predictions, multioutput='uniform_average')\n",
        "        rmse_global = np.sqrt(mse_global)\n",
        "        #individual metrics (for all traits together)\n",
        "        mae_list = mean_absolute_error(y, predictions, multioutput='raw_values').tolist()\n",
        "        mse_list = mean_squared_error(y, predictions, multioutput='raw_values').tolist()\n",
        "        rmse_list = list(map(np.sqrt, mse_list))\n",
        "        #results dictionary\n",
        "        testing_results = {\n",
        "            'MAE': mae_global,\n",
        "            'MSE': mse_global,\n",
        "            'RMSE': rmse_global,\n",
        "            'MAE_LIST': mae_list,\n",
        "            'MSE_LIST': mse_list,\n",
        "            'RMSE_LIST': rmse_list\n",
        "            #'predictions': predictions.tolist()\n",
        "        }\n",
        "    else:\n",
        "        #how many classes are wrong\n",
        "        mean_error = (sum( [sum(predictions[i] != y.values[i]) for i in np.arange(0, len(predictions))] )\n",
        "                      / (predictions.shape[0] * predictions.shape[1]))\n",
        "        #get transpose for the metrics\n",
        "        predictions_transpose = [*zip(*predictions)]\n",
        "        y_transpose = [*zip(*y.values)]\n",
        "        it_range = range(0, len(y_transpose))\n",
        "        #for micro-averaging in a multiclass setting with all labels included \n",
        "        #it will produce equal precision, recall and F\n",
        "        #https://simonhessner.de/why-are-precision-recall-and-f1-score-equal-when-using-micro-averaging-in-a-multi-class-problem/\n",
        "        f1_micro = [f1_score(y_transpose[i], predictions_transpose[i], average='micro') for i in it_range]\n",
        "        precision_micro = [precision_score(y_transpose[i], predictions_transpose[i], average='micro') for i in it_range]\n",
        "        recall_micro = [recall_score(y_transpose[i], predictions_transpose[i], average='micro') for i in it_range]\n",
        "        f1_macro = [f1_score(y_transpose[i], predictions_transpose[i], average='macro') for i in it_range]\n",
        "        precision_macro = [precision_score(y_transpose[i], predictions_transpose[i], average='macro') for i in it_range]\n",
        "        recall_macro = [recall_score(y_transpose[i], predictions_transpose[i], average='macro') for i in it_range]\n",
        "        #results dictionary\n",
        "        testing_results = {\n",
        "            'MEAN_ERROR': mean_error,\n",
        "            'F1': np.mean(f1_micro), \n",
        "            'PRECISION': np.mean(precision_micro),\n",
        "            'RECALL': np.mean(recall_micro), \n",
        "            'F1_MICRO': f1_micro,\n",
        "            'PRECISION_MICRO': precision_micro,\n",
        "            'RECALL_MICRO': recall_micro,\n",
        "            'F1_MACRO': f1_macro,\n",
        "            'PRECISION_MACRO': precision_macro,\n",
        "            'RECALL_MACRO': recall_macro\n",
        "            #'predictions': predictions.tolist()\n",
        "        }\n",
        "    #is to save a results file\n",
        "    if store_file:\n",
        "        save_file('Testing', testing_results, 0, 0, architecture, with_da, colab, testing=True)\n",
        "    return testing_results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWSyGtOe3fm0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "#####################################################\n",
        "#### Architecture Composing #########################\n",
        "#####################################################\n",
        "'''\n",
        "\n",
        "def run_architecture(df, architecture=1):\n",
        "    #split into X and y\n",
        "    X, y = split_x_y(df, architecture, testing=False)\n",
        "    #the multi-output model\n",
        "    param_grid = tuning_dictionary()\n",
        "    multi_estimators = build_model(architecture)\n",
        "    #train and save best model\n",
        "    scoring = ('neg_root_mean_squared_error' if architecture == 1 else None)\n",
        "    best_metric, best_estimator = find_best_model(multi_estimators, X, y, param_grid, \n",
        "                                                num_trials=NUM_TRIALS, outer_k_folds=OUTER_K_FOLDS, \n",
        "                                                inner_k_folds=INNER_K_FOLDS, num_iter=RANDOM_ITERATIONS,\n",
        "                                                scoring=scoring,\n",
        "                                                architecture=architecture, with_da=DA_DESC)\n",
        "    print('Best overall %s for architecture %d and %s is %.4f' %(('RMSE' if architecture == 1 else 'AUC'), architecture, DA_DESC, best_metric))\n",
        "    #store best model\n",
        "    save_best_estimator(best_estimator, architecture, DA_DESC, COLAB)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqNx9CWH-eIv",
        "colab_type": "code",
        "outputId": "bad6bcd7-8007-44d0-ffe1-afc53da7f3f4",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 465
        }
      },
      "source": [
        "'''\n",
        "#####################################################\n",
        "#### Main Execution #################################\n",
        "#####################################################\n",
        "'''\n",
        "\n",
        "#Global Vars\n",
        "COLAB = True\n",
        "ARCHITECTURE = 2\n",
        "WITH_DA = True\n",
        "DA_DESC = ('WithDa' if WITH_DA else 'NoDa')\n",
        "NUM_TRIALS = 2\n",
        "OUTER_K_FOLDS = 3\n",
        "INNER_K_FOLDS = 4\n",
        "RANDOM_ITERATIONS = 175\n",
        "\n",
        "#Read dataset\n",
        "df = read_dataset(WITH_DA, COLAB)\n",
        "run_architecture(df, architecture=ARCHITECTURE)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3faed993-9a40-467e-a982-60055266c204\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-3faed993-9a40-467e-a982-60055266c204\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving personality_final_WithDa_20200321.csv to personality_final_WithDa_20200321.csv\n",
            "Uploaded file \"personality_final_WithDa_20200321.csv\" with length 716470 bytes\n",
            "Fitting 4 folds for each of 175 candidates, totalling 700 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  9.4min\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 39.5min\n",
            "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed: 83.8min\n",
            "[Parallel(n_jobs=-1)]: Done 700 out of 700 | elapsed: 129.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Outer iteration 1 took 7762.979 s\n",
            "Fitting 4 folds for each of 175 candidates, totalling 700 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  7.2min\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 33.7min\n",
            "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed: 73.8min\n",
            "[Parallel(n_jobs=-1)]: Done 700 out of 700 | elapsed: 123.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Outer iteration 2 took 7418.638 s\n",
            "Fitting 4 folds for each of 175 candidates, totalling 700 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  8.6min\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed: 34.1min\n",
            "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed: 83.0min\n",
            "[Parallel(n_jobs=-1)]: Done 700 out of 700 | elapsed: 125.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Outer iteration 3 took 7520.902 s\n",
            "Best overall AUC for architecture 2 and WithDa is 0.4660\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}